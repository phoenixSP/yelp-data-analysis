CREATE TABLE IF NOT EXISTS flights.flight_data_date (   YEAR int, FL_DATE date,   UNIQUE_CARRIER STRING,   AIRLINE_ID int,   CARRIER STRING,   TAIL_NUM STRING,   FL_NUM int,   ORIGIN_AIRPORT_ID int,   ORIGIN_AIRPORT_SEQ_ID int, ORIGIN STRING,   DEST_AIRPORT_ID int,   DEST_AIRPORT_SEQ_ID int,   DEST STRING,   DEP_DELAY decimal,   ARR_DELAY decimal,   CANCELLED decimal,   DIVERTED decimal,   DISTANCE decimal ) PARTITIONED BY (month int, day_of_month int) ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde' WITH SERDEPROPERTIES  (     "separatorChar" = ",",     "quoteChar"="\"" )  LOCATION '/user/root/flight_data/';

FROM flights.flight_data_csv f INSERT INTO TABLE flights.flight_data_date PARTITION(month=12, day_of_month) SELECT f.year, f.fl_date, f.unique_carrier, f.airline_id, f.carrier,  f.tail_num, f.fl_num, f.origin_airport_id, f.origin_airport_seq_id,  f.origin, f.dest_airport_id, f.dest_airport_seq_id, f.dest, f.dep_delay,  f.arr_delay, f.cancelled, f.diverted, f.distance, f.day_of_month where  f.month=12; 

4.3.4
CREATE TABLE IF NOT EXISTS flights.flight_data_orc (   YEAR int, FL_DATE date,   UNIQUE_CARRIER STRING,   AIRLINE_ID int,   CARRIER STRING,   TAIL_NUM STRING,   FL_NUM int,   ORIGIN_AIRPORT_ID int,   ORIGIN_AIRPORT_SEQ_ID int, ORIGIN STRING,   DEST_AIRPORT_ID int,   DEST_AIRPORT_SEQ_ID int,   DEST STRING,   DEP_DELAY decimal,   ARR_DELAY decimal,   CANCELLED decimal,   DIVERTED decimal,   DISTANCE decimal ) PARTITIONED BY (month int, day_of_month int) STORED AS ORC;

FROM flights.flight_data_csv f INSERT INTO TABLE flights.flight_data_orc PARTITION(month=12, day_of_month) SELECT f.year, f.fl_date, f.unique_carrier, f.airline_id, f.carrier,  f.tail_num, f.fl_num, f.origin_airport_id, f.origin_airport_seq_id,  f.origin, f.dest_airport_id, f.dest_airport_seq_id, f.dest, f.dep_delay,  f.arr_delay, f.cancelled, f.diverted, f.distance, f.day_of_month where  f.month=12; 

REGISTER /usr/hdp/current/pig-client/piggybank.jar;
DEFINE CSVExcelStorage org.apache.pig.piggybank.storage.CSVExcelStorage;
RAW = LOAD '/user/root/flight_data/*_1.csv' 
USING CSVExcelStorage() AS (year:chararray, month:chararray, day_of_month:chararray, fl_date:chararray, unique_carrier:chararray, airline_id:chararray, carrier:chararray, tail_num:chararray, fl_num:chararray,origin_airport_id:chararray, origin_airport_seq_id:chararray, origin:chararray,dest_airport_id:chararray, dest_airport_seq_id:chararray, dest:chararray,dep_delay:chararray, arr_delay:chararray, cancelled:chararray,diverted:chararray, distance:chararray);C = FOREACH RAW GENERATE CONCAT(origin,'_',dest) AS rowkey:chararray,TOMAP('origin', origin,'destination', dest,CONCAT(fl_date,'_',tail_num), dep_delay) as dep:map[],TOMAP('origin', origin,'destination', dest,CONCAT(fl_date,'_',tail_num), arr_delay) AS arr:map[]; STORE C INTO 'hbase://flights:delays'USING org.apache.pig.backend.hadoop.hbase.HBaseStorage('dep:* arr:*');

WITH joined_data as (
select origin, dep_delay, description from flight_data_orc2 f 
join airport a on f.origin = a.code
)
select description, avg(dep_delay) as avg_delay from joined_data
group by description
order by avg_delay desc limit 1;

WITH joined_data as (
select carrier, arr_delay, description, fl_date from flight_data_orc2 f 
join carrier c on f.carrier = c.code
)
select description, sum(arr_delay) as avg_delay from joined_data
where fl_date = '2016-03-14'
group by description
order by avg_delay desc limit 1;

INSERT INTO TABLE flights.flight_data_denorm SELECT f.year, f.month, f.day_of_month, f.fl_date, f.unique_carrier, f.airline_id, f.carrier,  f.tail_num, f.fl_num, f.origin_airport_id, f.origin_airport_seq_id,  f.origin, f.dest_airport_id, f.dest_airport_seq_id, f.dest, f.dep_delay,  f.arr_delay, f.cancelled, f.diverted, f.distance, c.description, array(o.description, d.description) from flight_data_orc f inner join carrier c on f.carrier = c.code inner join airport o on f.origin = o.code inner join airport d on f.dest = d.code; 


hadoop jar  /usr/hdp/2.5.0.0-1245/hadoop-mapreduce/hadoop-streaming.jar -D mapred.reduce.tasks=16 -input /user/root/names/*.txt -mapper "python grep_search_updated.py" -file "grep_search_updated.py" -reducer "python grep_search_reduce.py" -file "grep_search_reduce.py" -output /user/root/grep_out -cmdenv SEARCH_STRING="Zyking"


